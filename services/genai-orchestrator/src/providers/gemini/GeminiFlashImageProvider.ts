import { GoogleGenAI } from '@google/genai'
import { Logger } from '@aws-lambda-powertools/logger'

import type { ModelConfig } from '@auteurium/shared-types'
import type { IImageProvider, ImageGenerationRequest, ImageGenerationResponse } from '../base/IImageProvider'
import { getModelsByProvider } from '../../config/models'
import { ModelProvider, GenerationModality } from '@auteurium/shared-types'

const logger = new Logger({ serviceName: 'gemini-flash-image-provider' })

/**
 * Gemini 2.5 Flash Image provider implementation
 * Uses Google Gen AI SDK for multimodal image generation
 * Supports text prompts + up to 3 input images
 */
export class GeminiFlashImageProvider implements IImageProvider {
  readonly name = 'gemini-flash-image'
  private client: GoogleGenAI | null = null
  private apiKey: string | null = null

  async initialize(apiKey: string): Promise<void> {
    this.apiKey = apiKey
    this.client = new GoogleGenAI({ apiKey })
    logger.info('Gemini Flash Image provider initialized')
  }

  async generate(): Promise<never> {
    throw new Error('Image provider does not support text generation. Use generateImage() instead.')
  }

  async generateImage(request: ImageGenerationRequest & { inputImages?: Array<{ data: Buffer; mimeType: string }> }): Promise<ImageGenerationResponse> {
    if (!this.client) {
      throw new Error('Gemini Flash Image provider not initialized. Call initialize() first.')
    }

    const startTime = Date.now()

    try {
      // Validate prompt
      await this.validatePrompt(request.prompt)

      // Validate input images count
      if (request.inputImages && request.inputImages.length > 3) {
        throw new Error(`Too many input images (${request.inputImages.length}). Maximum 3 images supported.`)
      }

      const aspectRatio = request.width && request.height
        ? `${request.width}:${request.height}`
        : '1:1'

      logger.info('Generating image with Gemini Flash Image', {
        modelId: request.modelId,
        promptLength: request.prompt.length,
        inputImagesCount: request.inputImages?.length ?? 0,
        aspectRatio
      })

      // Build multimodal contents array
      const contents: Array<{ text?: string; inlineData?: { data: string; mimeType: string } }> = []

      // Add text prompt
      contents.push({ text: request.prompt })

      // Add input images if provided
      if (request.inputImages && request.inputImages.length > 0) {
        for (const image of request.inputImages) {
          contents.push({
            inlineData: {
              data: image.data.toString('base64'),
              mimeType: image.mimeType
            }
          })
        }
      }

      // Generate image using Gemini Flash Image API
      // Note: Using 'as any' for config as the SDK types may not include all image generation options
      const response = await this.client.models.generateContent({
        model: request.modelId,
        contents,
        config: {
          responseModalities: ['IMAGE'],
          responseImageAspectRatio: aspectRatio
        } as any
      })

      if (!response || !response.candidates || response.candidates.length === 0) {
        throw new Error('No image generated by Gemini Flash Image')
      }

      const candidate = response.candidates[0]

      // Extract image data from response
      let imageData: unknown

      // Gemini Flash Image returns image in parts array
      if (candidate.content?.parts && Array.isArray(candidate.content.parts)) {
        for (const part of candidate.content.parts) {
          if ('inlineData' in part && part.inlineData) {
            const inlineData = part.inlineData as { data?: string; mimeType?: string }
            if (inlineData.data) {
              imageData = inlineData.data
              break
            }
          }
        }
      }

      if (!imageData) {
        throw new Error('Image data not found in Gemini Flash Image response')
      }

      // Convert base64 string to Buffer if needed
      let imageBuffer: Buffer
      if (typeof imageData === 'string') {
        imageBuffer = Buffer.from(imageData, 'base64')
      } else {
        throw new Error(`Unexpected image data type: ${typeof imageData}`)
      }

      // Parse aspect ratio to get dimensions
      const [widthRatio, heightRatio] = aspectRatio.split(':').map(Number)
      const baseSize = 1024
      const width = aspectRatio === '1:1' ? baseSize : Math.round(baseSize * widthRatio / Math.max(widthRatio, heightRatio))
      const height = aspectRatio === '1:1' ? baseSize : Math.round(baseSize * heightRatio / Math.max(widthRatio, heightRatio))

      const generationTimeMs = Date.now() - startTime
      const cost = this.calculateCost(1, request.modelId)

      logger.info('Image generation completed', {
        modelId: request.modelId,
        cost,
        generationTimeMs,
        width,
        height,
        inputImagesUsed: request.inputImages?.length ?? 0
      })

      return {
        image: {
          type: 'image',
          url: '', // Will be set after S3 upload
          s3Key: '', // Will be set after S3 upload
          metadata: {
            width,
            height,
            aspectRatio,
            format: 'png',
            generatedAt: new Date().toISOString()
          }
        },
        imageData: imageBuffer, // Include raw image data for upload
        tokensUsed: 1290, // Gemini Flash Image uses 1290 tokens per image
        cost,
        modelUsed: request.modelId,
        generationTimeMs
      } as ImageGenerationResponse & { imageData: Buffer }
    } catch (error) {
      logger.error('Image generation failed', {
        error: error instanceof Error ? error.message : String(error),
        modelId: request.modelId
      })
      throw error
    }
  }

  async getAvailableModels(): Promise<ModelConfig[]> {
    const models = getModelsByProvider(ModelProvider.GEMINI)
    return models.filter(model => model.modality === GenerationModality.TEXT_AND_IMAGE_TO_IMAGE)
  }

  isModelSupported(modelId: string): boolean {
    const models = getModelsByProvider(ModelProvider.GEMINI)
    return models.some(model => model.modelId === modelId && model.modality === GenerationModality.TEXT_AND_IMAGE_TO_IMAGE)
  }

  calculateCost(imagesGenerated: number, modelId: string): number {
    const models = getModelsByProvider(ModelProvider.GEMINI)
    const model = models.find(m => m.modelId === modelId)

    if (!model || !model.costPerToken) {
      logger.warn('Cost per image not configured for model', { modelId })
      return 0
    }

    // For Gemini Flash Image, costPerToken represents cost per image
    return imagesGenerated * model.costPerToken
  }

  async validatePrompt(prompt: string): Promise<boolean> {
    if (!prompt || prompt.trim().length === 0) {
      throw new Error('Prompt cannot be empty')
    }

    // Gemini Flash Image has a reasonable prompt length limit
    if (prompt.length > 8000) {
      throw new Error('Prompt exceeds maximum length of 8000 characters')
    }

    return true
  }

  getSupportedSizes(): Array<{ width: number; height: number }> {
    // Gemini Flash Image supports various aspect ratios up to 21:9
    return [
      { width: 1024, height: 1024 }, // 1:1
      { width: 768, height: 1024 },  // 3:4
      { width: 1024, height: 768 },  // 4:3
      { width: 576, height: 1024 },  // 9:16
      { width: 1024, height: 576 },  // 16:9
      { width: 1024, height: 488 },  // 21:9
      { width: 488, height: 1024 }   // 9:21
    ]
  }
}
